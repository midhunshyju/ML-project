# -*- coding: utf-8 -*-
"""flood_risk_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BmA5YN_Lz4gP7SZ7iNMkYf_0mNqYQpVm
"""

import pandas as pd
import numpy as np
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,roc_curve,auc
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
import warnings

df=pd.read_csv('/content/flood_risk_dataset_india.csv')
df

df1=df.head(5500)
df1

df1.columns

df1.isna().sum()

df1.dtypes

df1['Land Cover'].value_counts()

df1['Soil Type'].value_counts()

dflandcover=df1['Land Cover']

count=dflandcover.value_counts()
explode = [0.1 if i == 0 else 0 for i in range (len(count))]
plt.figure(figsize=(10,6))
plt.pie(count,labels=count.index,autopct='%1.1f%%', startangle=90,shadow=True,explode=explode)
plt.title('Proportions of Land Covers')
plt.show()

"""The Desert segment is slightly separated (exploded) from the rest, likely to highlight its significance in the overall land cover composition."""

dfsoil=df1['Soil Type']

count=dfsoil.value_counts()
explode = [0.1 if i == 0 else 0 for i in range (len(count))]
plt.figure(figsize=(10,6))
plt.pie(count,labels=count.index,autopct='%1.1f%%', startangle=90,shadow=True,explode=explode)
plt.title('Proportions of Soil Types')
plt.show()

"""Largest Category: "Silt" has the highest proportion at 20.7%, indicating it is the most prevalent soil type.

"""

sns.barplot(x='Soil Type',y='Water Level (m)',data=df1)
plt.title('Soil Type vs Water Level')
plt.xlabel('Soil Type')
plt.ylabel('Water level (m)')
plt.show()

warnings.filterwarnings("ignore")

sns.histplot(x='Rainfall (mm)', hue='Flood Occurred', data=df1,multiple='stack')

"""The water level remains fairly constant across all soil types, hovering around 5 meters, with only slight variations.

The small error bars suggest there is minor uncertainty or variability in the water level measurements for each soil type.
"""

columns=['Land Cover','Soil Type']
encoder=LabelEncoder()
for col in columns:
  df1[col]=encoder.fit_transform(df1[col])

sns.boxplot(df1)

""".The graph states that there are no outliers detected in any of the categories."""

df1

plt.figure(figsize=(10,8))
plt.title("Correlation Map")
sns.heatmap(df1.corr(),annot=True, fmt='.2f')
plt.show()

"""

1.Water Level (m) & River Discharge (m³/s): Strongest correlation (~1.00), meaning an increase in river discharge directly affects water levels.
2.   List item

"""

important_features = ['Rainfall (mm)', 'Temperature (°C)', 'Humidity (%)', 'Water Level (m)', 'Flood Occurred']
sns.pairplot(df[important_features], hue='Flood Occurred', diag_kind='kde')
plt.show()

# important_features = ['Rainfall (mm)','Water Level (m)','River Discharge (m³/s)','Historical Floods','Infrastructure','Land Cover','Soil Type']
# df1=df1[important_features]

"""



*  Rainfall, Humidity, and Water Level appear to have a bimodal or slightly skewed distribution.
*   Temperature has a more uniform distribution.
*   The scatter plots suggest that floods (orange points) occur across a broad range of values for most variables.

"""

X=df1.iloc[:,:-1]
y=df1.iloc[:,-1]

scaler=StandardScaler()
X_scaled=scaler.fit_transform(X)
X_scaled

X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.3,random_state=1  )

rf=RandomForestClassifier(n_estimators=100,max_depth=6,random_state=1)
gb=GradientBoostingClassifier(n_estimators=100)
xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6)
svc=SVC(kernel='poly')
adb = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)
nb=GaussianNB()
lg=LogisticRegression()

models=[rf,gb,xgb,lg]
for model in models:
  print('********************',model,'*********************')
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print('Classification_report:',classification_report(y_test,y_pred))

from imblearn.over_sampling import SMOTE
from collections import Counter


print("Class distribution before SMOTE:", Counter(y_train))


smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)


print("Class distribution after SMOTE:", Counter(y_train_resampled))

models=[rf,gb,xgb,lg]
for model in models:
  print('********************',model,'*********************')
  model.fit(X_train_resampled,y_train_resampled)
  y_pred=model.predict(X_test)
  print('Classification_report:',classification_report(y_test,y_pred))

param_grid_rf = {
    'n_estimators': [100, 200, 300, 500],
    'max_depth': [10, 20, 30],
}
param_grid_gb = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 10],
}
param_grid_lg = {
    'C': [0.1, 1, 10],
    'solver': ['liblinear', 'lbfgs'],
}

#  Random Forest
grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5)
grid_search_rf.fit(X_train, y_train)
print("Best Parameters for RF:", grid_search_rf.best_params_)
print("Best Accuracy for RF:", grid_search_rf.best_score_)

#  Gradient Boosting
grid_search_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5)
grid_search_gb.fit(X_train, y_train)
print("Best Parameters for GB:", grid_search_gb.best_params_)
print("Best Accuracy for GB:", grid_search_gb.best_score_)

#linear regression
grid_search_lg = GridSearchCV(estimator=lg, param_grid=param_grid_lg, cv=5)
grid_search_lg.fit(X_train, y_train)
print("Best Parameters for lg:", grid_search_lg.best_params_)
print("Best Accuracy for lg:", grid_search_lg.best_score_)

best_model=rf
y_probs = best_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

pickle.dump(scaler,open('scaler.sav','wb'))

import pickle
pickle.dump(rf,open('Random_forest.sav','wb'))





